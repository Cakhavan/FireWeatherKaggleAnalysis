{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bittestconda42a2969441114a6a9156acaea3a0c1c0",
   "display_name": "Python 3.7.6 64-bit ('test': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets \n",
    "from sklearn.feature_selection import RFE \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "FIRE_YEAR STAT_CAUSE_DESCR   LATITUDE   LONGITUDE STATE COUNTY  FIPS_NAME  \\\n0       2005    Miscellaneous  40.036944 -121.005833    CA     63     Plumas   \n1       2004        Lightning  38.933056 -120.404444    CA     61     Placer   \n2       2004   Debris Burning  38.984167 -120.735556    CA     17  El Dorado   \n3       2004        Lightning  38.559167 -119.913333    CA      3     Alpine   \n4       2004        Lightning  38.559167 -119.933056    CA      3     Alpine   \n\n   DISCOVERY_DATE  CONT_DATE  FIRE_SIZE  DISCOVERY_DOY DISCOVERY_TIME  \\\n0       2453403.5  2453403.5       0.10             33           1300   \n1       2453137.5  2453137.5       0.25            133           0845   \n2       2453156.5  2453156.5       0.10            152           1921   \n3       2453184.5  2453189.5       0.10            180           1600   \n4       2453184.5  2453189.5       0.10            180           1600   \n\n        DATE   END_DATE  \n0 2005-02-02 2005-02-02  \n1 2004-05-12 2004-05-12  \n2 2004-05-31 2004-05-31  \n3 2004-06-28 2004-07-03  \n4 2004-06-28 2004-07-03  \n"
    }
   ],
   "source": [
    "# read fire data\n",
    "conn = sqlite3.connect('FPA_FOD_20170508.sqlite')\n",
    "df = pd.read_sql_query(\"SELECT FIRE_YEAR, STAT_CAUSE_DESCR, LATITUDE, LONGITUDE, STATE, COUNTY, FIPS_NAME, DISCOVERY_DATE, CONT_DATE, FIRE_SIZE, DISCOVERY_DOY, DISCOVERY_TIME FROM 'Fires'\", conn)\n",
    "df['DATE'] = pd.to_datetime(df['DISCOVERY_DATE'] - pd.Timestamp(0).to_julian_date(), unit='D')\n",
    "df['END_DATE'] = pd.to_datetime(df['CONT_DATE'] - pd.Timestamp(0).to_julian_date(), unit='D')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "FIRE_YEAR   STAT_CAUSE_DESCR   LATITUDE   LONGITUDE STATE COUNTY  \\\n0             2005      Miscellaneous  40.036944 -121.005833    CA     63   \n1             2004          Lightning  38.933056 -120.404444    CA     61   \n2             2004     Debris Burning  38.984167 -120.735556    CA     17   \n3             2004          Lightning  38.559167 -119.913333    CA      3   \n4             2004          Lightning  38.559167 -119.933056    CA      3   \n...            ...                ...        ...         ...   ...    ...   \n1880460       2015  Missing/Undefined  40.481637 -122.389375    CA   None   \n1880461       2015      Miscellaneous  37.617619 -120.938570    CA   None   \n1880462       2015  Missing/Undefined  37.617619 -120.938570    CA   None   \n1880463       2015  Missing/Undefined  37.672235 -120.898356    CA   None   \n1880464       2015      Miscellaneous  34.263217 -116.830950    CA   None   \n\n         FIPS_NAME  DISCOVERY_DATE  CONT_DATE  FIRE_SIZE  DISCOVERY_DOY  \\\n0           Plumas       2453403.5  2453403.5       0.10             33   \n1           Placer       2453137.5  2453137.5       0.25            133   \n2        El Dorado       2453156.5  2453156.5       0.10            152   \n3           Alpine       2453184.5  2453189.5       0.10            180   \n4           Alpine       2453184.5  2453189.5       0.10            180   \n...            ...             ...        ...        ...            ...   \n1880460       None       2457291.5  2457291.5       0.01            269   \n1880461       None       2457300.5        NaN       0.20            278   \n1880462       None       2457144.5        NaN       0.10            122   \n1880463       None       2457309.5        NaN       2.00            287   \n1880464       None       2457095.5        NaN       0.10             73   \n\n        DISCOVERY_TIME       DATE   END_DATE TIME       DATETIME  \n0                 1300 2005-02-02 2005-02-02   13  2005-02-02 13  \n1                 0845 2004-05-12 2004-05-12   08  2004-05-12 08  \n2                 1921 2004-05-31 2004-05-31   19  2004-05-31 19  \n3                 1600 2004-06-28 2004-07-03   16  2004-06-28 16  \n4                 1600 2004-06-28 2004-07-03   16  2004-06-28 16  \n...                ...        ...        ...  ...            ...  \n1880460           1726 2015-09-26 2015-09-26   17  2015-09-26 17  \n1880461           0126 2015-10-05        NaT   01  2015-10-05 01  \n1880462           2052 2015-05-02        NaT   20  2015-05-02 20  \n1880463           2309 2015-10-14        NaT   23  2015-10-14 23  \n1880464           2128 2015-03-14        NaT   21  2015-03-14 21  \n\n[1880465 rows x 16 columns]\n"
    }
   ],
   "source": [
    "# Extract and reformat DATETIME for easy lookup for fire data\n",
    "df['TIME'] = df['DISCOVERY_TIME'].str[0:2]\n",
    "df['DATETIME'] = df['DATE'].dt.strftime('%Y-%m-%d') + ' ' +  df['TIME']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "FIRE_YEAR   STAT_CAUSE_DESCR   LATITUDE   LONGITUDE STATE COUNTY  \\\n1563819       2012           Campfire  45.991944 -113.471389    MT    039   \n1563820       2012           Campfire  45.946667 -112.366111    MT    043   \n1563821       2012           Campfire  45.418611 -111.855833    MT    057   \n1563822       2012           Campfire  46.219167 -112.243333    MT    093   \n1563823       2012          Lightning  44.942222 -113.458611    MT    001   \n...            ...                ...        ...         ...   ...    ...   \n1880460       2015  Missing/Undefined  40.481637 -122.389375    CA   None   \n1880461       2015      Miscellaneous  37.617619 -120.938570    CA   None   \n1880462       2015  Missing/Undefined  37.617619 -120.938570    CA   None   \n1880463       2015  Missing/Undefined  37.672235 -120.898356    CA   None   \n1880464       2015      Miscellaneous  34.263217 -116.830950    CA   None   \n\n          FIPS_NAME  DISCOVERY_DATE  CONT_DATE  FIRE_SIZE  DISCOVERY_DOY  \\\n1563819     Granite       2456172.5  2456174.5       0.10            246   \n1563820   Jefferson       2456062.5  2456062.5       0.10            136   \n1563821     Madison       2456034.5  2456034.5       0.01            108   \n1563822  Silver Bow       2456237.5  2456237.5       0.10            311   \n1563823  Beaverhead       2456152.5  2456153.5       0.10            226   \n...             ...             ...        ...        ...            ...   \n1880460        None       2457291.5  2457291.5       0.01            269   \n1880461        None       2457300.5        NaN       0.20            278   \n1880462        None       2457144.5        NaN       0.10            122   \n1880463        None       2457309.5        NaN       2.00            287   \n1880464        None       2457095.5        NaN       0.10             73   \n\n        DISCOVERY_TIME       DATE   END_DATE TIME       DATETIME  \n1563819           1300 2012-09-02 2012-09-04   13  2012-09-02 13  \n1563820           1517 2012-05-15 2012-05-15   15  2012-05-15 15  \n1563821           1844 2012-04-17 2012-04-17   18  2012-04-17 18  \n1563822           1402 2012-11-06 2012-11-06   14  2012-11-06 14  \n1563823           0828 2012-08-13 2012-08-14   08  2012-08-13 08  \n...                ...        ...        ...  ...            ...  \n1880460           1726 2015-09-26 2015-09-26   17  2015-09-26 17  \n1880461           0126 2015-10-05        NaT   01  2015-10-05 01  \n1880462           2052 2015-05-02        NaT   20  2015-05-02 20  \n1880463           2309 2015-10-14        NaT   23  2015-10-14 23  \n1880464           2128 2015-03-14        NaT   21  2015-03-14 21  \n\n[279793 rows x 16 columns]\n"
    }
   ],
   "source": [
    "# Prune years not in range 2012-2015 for fire data\n",
    "df = df[df['FIRE_YEAR'] >= 2012]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Weather Data\n",
    "# df_fire = pd.read_csv('California_Fire_Incidents.csv')\n",
    "df_humidity = pd.read_csv('humidity.csv')\n",
    "df_pressure = pd.read_csv('pressure.csv')\n",
    "df_temp = pd.read_csv('temperature.csv')\n",
    "df_weather = pd.read_csv('weather_description.csv')\n",
    "df_wind_direction = pd.read_csv('wind_direction.csv')\n",
    "df_wind_speed = pd.read_csv('wind_speed.csv')\n",
    "df_city_attributes = pd.read_csv('city_attributes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune Irrelevant Cities\n",
    "cities = df_humidity.columns.drop(['Jerusalem', 'Haifa', 'Eilat', 'Tel Aviv District', 'Beersheba', 'Nahariyya'])\n",
    "df_humidity = df_humidity[cities]\n",
    "df_pressure = df_pressure[cities]\n",
    "df_temp = df_temp[cities]\n",
    "df_weather = df_weather[cities]\n",
    "df_wind_direction = df_wind_direction[cities]\n",
    "df_wind_speed = df_wind_speed[cities]\n",
    "# df_city_attributes = df_city_attributes[cities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all cities common between forest fire data and weather data\n",
    "common_cities = []\n",
    "for city in cities:\n",
    "    if(len(df.loc[df['FIPS_NAME']==city]) != 0):\n",
    "        common_cities.append(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "FIRE_YEAR   STAT_CAUSE_DESCR   LATITUDE   LONGITUDE STATE  \\\n1567432       2012      Miscellaneous  34.204167 -117.808333    CA   \n1567433       2012          Lightning  34.345278 -117.928889    CA   \n1567434       2012      Miscellaneous  34.548056 -118.671667    CA   \n1567436       2012      Equipment Use  34.489444 -118.285833    CA   \n1567437       2012           Children  34.467778 -118.530833    CA   \n...            ...                ...        ...         ...   ...   \n1872185       2015  Missing/Undefined  33.387140 -117.174866    CA   \n1872229       2015     Debris Burning  33.226976 -117.024311    CA   \n1872237       2015  Missing/Undefined  34.666666 -118.766666    CA   \n1872244       2015  Missing/Undefined  33.388859 -117.255707    CA   \n1872247       2015     Debris Burning  33.243255 -117.241177    CA   \n\n              COUNTY    FIPS_NAME  DISCOVERY_DATE  CONT_DATE  FIRE_SIZE  \\\n1567432          037  Los Angeles       2456104.5  2456104.5       0.10   \n1567433          037  Los Angeles       2456180.5  2456180.5       0.10   \n1567434          037  Los Angeles       2456236.5  2456236.5       0.25   \n1567436          037  Los Angeles       2456106.5  2456106.5       0.10   \n1567437          037  Los Angeles       2456099.5  2456099.5       0.60   \n...              ...          ...             ...        ...        ...   \n1872185    SAN DIEGO    San Diego       2457354.5        NaN       0.10   \n1872229    SAN DIEGO    San Diego       2457385.5        NaN       0.10   \n1872237  LOS ANGELES  Los Angeles       2457330.5        NaN       0.12   \n1872244    SAN DIEGO    San Diego       2457308.5        NaN       0.25   \n1872247    SAN DIEGO    San Diego       2457365.5        NaN       0.10   \n\n         DISCOVERY_DOY DISCOVERY_TIME       DATE   END_DATE TIME  \\\n1567432            178           1030 2012-06-26 2012-06-26   10   \n1567433            254           1010 2012-09-10 2012-09-10   10   \n1567434            310           1349 2012-11-05 2012-11-05   13   \n1567436            180           1020 2012-06-28 2012-06-28   10   \n1567437            173           1814 2012-06-21 2012-06-21   18   \n...                ...            ...        ...        ...  ...   \n1872185            332           1502 2015-11-28        NaT   15   \n1872229            363           1711 2015-12-29        NaT   17   \n1872237            308           1440 2015-11-04        NaT   14   \n1872244            286           0314 2015-10-13        NaT   03   \n1872247            343           1646 2015-12-09        NaT   16   \n\n              DATETIME  \n1567432  2012-06-26 10  \n1567433  2012-09-10 10  \n1567434  2012-11-05 13  \n1567436  2012-06-28 10  \n1567437  2012-06-21 18  \n...                ...  \n1872185  2015-11-28 15  \n1872229  2015-12-29 17  \n1872237  2015-11-04 14  \n1872244  2015-10-13 03  \n1872247  2015-12-09 16  \n\n[3722 rows x 16 columns]\n"
    }
   ],
   "source": [
    "# Prune all cities not common between forest fire data and weather data\n",
    "df = df[df['FIPS_NAME'].isin(common_cities)]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "time  humidity  pressure  temperature       weather  \\\n0       2012-10-01 13:00:00      88.0    1009.0   289.480000    light rain   \n1       2012-10-01 14:00:00      87.0    1009.0   289.474993  sky is clear   \n2       2012-10-01 15:00:00      86.0    1009.0   289.460618  sky is clear   \n3       2012-10-01 16:00:00      85.0    1009.0   289.446243  sky is clear   \n4       2012-10-01 17:00:00      84.0    1009.0   289.431869  sky is clear   \n...                     ...       ...       ...          ...           ...   \n362011  2017-11-29 20:00:00       NaN       NaN          NaN           NaN   \n362012  2017-11-29 21:00:00       NaN       NaN          NaN           NaN   \n362013  2017-11-29 22:00:00       NaN       NaN          NaN           NaN   \n362014  2017-11-29 23:00:00       NaN       NaN          NaN           NaN   \n362015  2017-11-30 00:00:00       NaN       NaN          NaN           NaN   \n\n        wind direction  wind speed           city  \n0                150.0         2.0  San Francisco  \n1                147.0         2.0  San Francisco  \n2                141.0         2.0  San Francisco  \n3                135.0         2.0  San Francisco  \n4                129.0         2.0  San Francisco  \n...                ...         ...            ...  \n362011             NaN         NaN       New York  \n362012             NaN         NaN       New York  \n362013             NaN         NaN       New York  \n362014             NaN         NaN       New York  \n362015             NaN         NaN       New York  \n\n[362016 rows x 8 columns]\n"
    }
   ],
   "source": [
    "# Combine and Restructure all weather dataframes into one DataFrame and append a city column\n",
    "columns = ['time', 'humidity', 'pressure', 'temperature', 'weather', 'wind direction', 'wind speed']\n",
    "df_weatherdata = pd.DataFrame()\n",
    "for city in common_cities:\n",
    "    newdf = pd.DataFrame(pd.concat([df_humidity['datetime'], df_humidity[city], df_pressure[city], df_temp[city], df_weather[city], df_wind_direction[city], df_wind_speed[city]], axis=1, keys=columns))\n",
    "    newdf['city'] = city\n",
    "    df_weatherdata = df_weatherdata.append(newdf, ignore_index=True)\n",
    "print(df_weatherdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0         2012-10-01 13\n1         2012-10-01 14\n2         2012-10-01 15\n3         2012-10-01 16\n4         2012-10-01 17\n              ...      \n362011    2017-11-29 20\n362012    2017-11-29 21\n362013    2017-11-29 22\n362014    2017-11-29 23\n362015    2017-11-30 00\nName: DATETIME, Length: 362016, dtype: object\n"
    }
   ],
   "source": [
    "# Combine Date and Time for Easy Lookup\n",
    "df_weatherdata['DATE'] = df_weatherdata['time'].str[0:11]\n",
    "df_weatherdata['TIME'] = df_weatherdata['time'].str.split(\":\").str[0].str[11:]\n",
    "df_weatherdata['DATETIME'] = df_weatherdata['DATE'] + df_weatherdata['TIME']\n",
    "print(df_weatherdata['DATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0         2012-10-01 \n1         2012-10-01 \n2         2012-10-01 \n3         2012-10-01 \n4         2012-10-01 \n             ...     \n345234    2015-12-31 \n345235    2015-12-31 \n345236    2015-12-31 \n345237    2015-12-31 \n345238    2015-12-31 \nName: DATE, Length: 227800, dtype: object\n"
    }
   ],
   "source": [
    "# Prune years that arent between 2012-2015\n",
    "df_weatherdata = df_weatherdata[~(df_weatherdata['DATE'].astype(str).str.contains('2016') | df_weatherdata['DATE'].astype(str).str.contains('2017'))]\n",
    "print(df_weatherdata['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0         2012-10-01 13 San Francisco\n1         2012-10-01 14 San Francisco\n2         2012-10-01 15 San Francisco\n3         2012-10-01 16 San Francisco\n4         2012-10-01 17 San Francisco\n                     ...             \n345234         2015-12-31 19 New York\n345235         2015-12-31 20 New York\n345236         2015-12-31 21 New York\n345237         2015-12-31 22 New York\n345238         2015-12-31 23 New York\nName: DATETIME_CITY, Length: 227800, dtype: object\n"
    }
   ],
   "source": [
    "# Combine DATETIME and Cities for easy lookup for weather data\n",
    "df_weatherdata['DATETIME_CITY'] = df_weatherdata['DATETIME'] + ' ' + df_weatherdata['city']\n",
    "print(df_weatherdata['DATETIME_CITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1567432    2012-06-26 10 Los Angeles\n1567433    2012-09-10 10 Los Angeles\n1567434    2012-11-05 13 Los Angeles\n1567436    2012-06-28 10 Los Angeles\n1567437    2012-06-21 18 Los Angeles\n                     ...            \n1872185      2015-11-28 15 San Diego\n1872229      2015-12-29 17 San Diego\n1872237    2015-11-04 14 Los Angeles\n1872244      2015-10-13 03 San Diego\n1872247      2015-12-09 16 San Diego\nName: DATETIME_CITY, Length: 3722, dtype: object\n"
    }
   ],
   "source": [
    "# Combine DATETIME and Cities for easy lookup for forest fire data\n",
    "df['DATETIME_CITY'] = df['DATETIME'].astype(str) + ' ' + df['FIPS_NAME']\n",
    "print(df['DATETIME_CITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weatherdata['FIRE_DAYS'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "humidity  pressure  temperature               weather  wind direction  \\\n14176       69.0    1017.0   294.270000          sky is clear           271.0   \n14221        NaN    1014.0   292.180000                  haze           334.0   \n20087      100.0    1038.0   282.415000         broken clouds           219.0   \n21515       77.0    1030.0   289.181500       overcast clouds           288.0   \n24145       87.0    1012.0   289.090000                   fog           290.0   \n...          ...       ...          ...                   ...             ...   \n344254      45.0    1025.0   282.632909  heavy intensity rain           312.0   \n344487      60.0    1030.0   276.642214         broken clouds            25.0   \n344558      66.0    1011.0   281.390000      scattered clouds           270.0   \n344607      65.0    1039.0   280.294636          sky is clear            15.0   \n344995      53.0    1025.0   283.583269       overcast clouds           223.0   \n\n        wind speed           city       DATETIME  FIRE_DAYS  FIRE  \n14176          2.0  San Francisco  2014-05-15 05      False  True  \n14221          1.0  San Francisco  2014-05-17 02      False  True  \n20087          1.0  San Francisco  2015-01-16 12      False  True  \n21515          1.0  San Francisco  2015-03-17 00      False  True  \n24145          3.0  San Francisco  2015-07-04 14      False  True  \n...            ...            ...            ...        ...   ...  \n344254         4.0       New York  2015-11-20 23      False  True  \n344487         6.0       New York  2015-11-30 16      False  True  \n344558         5.0       New York  2015-12-03 15      False  True  \n344607         1.0       New York  2015-12-05 16      False  True  \n344995         4.0       New York  2015-12-21 20      False  True  \n\n[1806 rows x 10 columns]\n"
    }
   ],
   "source": [
    "# Create a Fire column to track which datetimes in which cities had fires occur\n",
    "df_weatherdata['FIRE'] = False\n",
    "df_weatherdata['FIRE'][df_weatherdata.loc[df_weatherdata['DATETIME_CITY'].isin(df['DATETIME_CITY'].values)].index] = True\n",
    "df_weatherdata = df_weatherdata[df_weatherdata.columns.drop(['time', 'DATE', 'TIME', 'DATETIME_CITY'])]\n",
    "print(df_weatherdata.loc[df_weatherdata['FIRE']==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weatherdata['HOUR'] = df_weatherdata['DATETIME'].str[11:]\n",
    "df_weatherdata['DAY'] = df_weatherdata['DATETIME'].str[8:10]\n",
    "df_weatherdata['MONTH'] = df_weatherdata['DATETIME'].str[5:7]\n",
    "df_weatherdata['YEAR'] = df_weatherdata['DATETIME'].str[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_weatherdata[df_weatherdata.columns.drop(['FIRE', 'FIRE_DAYS', 'DATETIME'])]\n",
    "y = df_weatherdata['FIRE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "humidity  pressure  temperature          weather  wind direction  \\\n149434      77.0    1008.0   292.910000  overcast clouds           170.0   \n140854      45.0    1007.0   300.830000       few clouds           140.0   \n288700      81.0    1027.0   303.429333     sky is clear           218.0   \n316913      50.0    1007.0   297.400000    broken clouds           250.0   \n91933       72.0    1023.0   288.200000    broken clouds             0.0   \n...          ...       ...          ...              ...             ...   \n186987      65.0    1013.0   304.310000     sky is clear            84.0   \n154025      55.0    1043.0   284.482000     sky is clear           110.0   \n199040      46.0    1031.0   299.098500     sky is clear            77.0   \n230752      66.0    1016.0   286.700000  overcast clouds           340.0   \n189066      79.0    1010.0   299.130000     sky is clear           203.0   \n\n        wind speed       city HOUR DAY MONTH  YEAR  \n149434         6.0     Dallas   11  24    04  2014  \n140854         7.0     Dallas   23  01    05  2013  \n288700         3.0      Miami   17  17    09  2014  \n316913         5.0   New York   18  07    10  2012  \n91933          0.0  San Diego   02  30    11  2012  \n...            ...        ...  ...  ..   ...   ...  \n186987         0.0    Houston   16  07    06  2013  \n154025         4.0     Dallas   18  01    11  2014  \n199040         3.0    Houston   21  22    10  2014  \n230752         4.0  Charlotte   17  06    04  2013  \n189066         2.0    Houston   07  02    09  2013  \n\n[152626 rows x 11 columns]\n"
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>humidity</th>\n      <th>pressure</th>\n      <th>temperature</th>\n      <th>weather</th>\n      <th>wind direction</th>\n      <th>wind speed</th>\n      <th>city</th>\n      <th>HOUR</th>\n      <th>DAY</th>\n      <th>MONTH</th>\n      <th>YEAR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>298441</th>\n      <td>78.0</td>\n      <td>1016.0</td>\n      <td>298.93000</td>\n      <td>mist</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Miami</td>\n      <td>14</td>\n      <td>28</td>\n      <td>10</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>298442</th>\n      <td>78.0</td>\n      <td>1015.0</td>\n      <td>298.93505</td>\n      <td>broken clouds</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Miami</td>\n      <td>15</td>\n      <td>28</td>\n      <td>10</td>\n      <td>2015</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        humidity  pressure  temperature        weather  wind direction  \\\n298441      78.0    1016.0    298.93000           mist             NaN   \n298442      78.0    1015.0    298.93505  broken clouds             NaN   \n\n        wind speed   city HOUR DAY MONTH  YEAR  \n298441         NaN  Miami   14  28    10  2015  \n298442         NaN  Miami   15  28    10  2015  "
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating bool series True for NaN values  \n",
    "bool_series = pd.isnull(X_train[\"wind speed\"])  \n",
    "    \n",
    "# filtering data  \n",
    "# displaying data only with Gender = NaN  \n",
    "X_train[bool_series]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['humidity'] = X_train['humidity'].fillna(method ='pad')\n",
    "X_train['pressure'] = X_train['pressure'].fillna(method ='pad')\n",
    "X_train['temperature'] = X_train['temperature'].fillna(method ='pad')\n",
    "X_train['wind direction'] = X_train['wind direction'].fillna(method ='pad')\n",
    "X_train['wind speed'] = X_train['wind speed'].fillna(method ='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['humidity'] = X_test['humidity'].fillna(method ='pad')\n",
    "X_test['pressure'] = X_test['pressure'].fillna(method ='pad')\n",
    "X_test['temperature'] = X_test['temperature'].fillna(method ='pad')\n",
    "X_test['wind direction'] = X_test['wind direction'].fillna(method ='pad')\n",
    "X_test['wind speed'] = X_test['wind speed'].fillna(method ='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Encode Labels\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "X_train['weather'] = encoder.fit_transform(X_train['weather'])\n",
    "X_train['city'] = encoder.fit_transform(X_train['city'])\n",
    "\n",
    "X_test['weather'] = encoder.fit_transform(X_test['weather'])\n",
    "X_test['city'] = encoder.fit_transform(X_test['city'])\n",
    "\n",
    "# Encode DATETIME in a way that preserves its cyclical nature\n",
    "X_train['HOUR_SIN'] = np.sin(X_train['HOUR'].astype(float)*(2.*np.pi/24))\n",
    "X_train['HOUR_COS'] = np.cos(X_train['HOUR'].astype(float)*(2.*np.pi/24))\n",
    "X_train['DAY_SIN'] = np.sin(X_train['DAY'].astype(float)*(2.*np.pi/30))\n",
    "X_train['DAY_COS'] = np.cos(X_train['DAY'].astype(float)*(2.*np.pi/30))\n",
    "X_train['MONTH_SIN'] = np.sin(X_train['MONTH'].astype(float)*(2.*np.pi/12))\n",
    "X_train['MONTH_COS'] = np.cos(X_train['MONTH'].astype(float)*(2.*np.pi/12))\n",
    "\n",
    "X_test['HOUR_SIN'] = np.sin(X_test['HOUR'].astype(float)*(2.*np.pi/24))\n",
    "X_test['HOUR_COS'] = np.cos(X_test['HOUR'].astype(float)*(2.*np.pi/24))\n",
    "X_test['DAY_SIN'] = np.sin(X_test['DAY'].astype(float)*(2.*np.pi/30))\n",
    "X_test['DAY_COS'] = np.cos(X_test['DAY'].astype(float)*(2.*np.pi/30))\n",
    "X_test['MONTH_SIN'] = np.sin(X_test['MONTH'].astype(float)*(2.*np.pi/12))\n",
    "X_test['MONTH_COS'] = np.cos(X_test['MONTH'].astype(float)*(2.*np.pi/12))\n",
    "\n",
    "X_train['YEAR'] = X_train['YEAR'].astype(float)\n",
    "X_test['YEAR'] = X_test['YEAR'].astype(float)\n",
    "\n",
    "X_train = X_train[X_train.columns.drop(['HOUR', 'DAY', 'MONTH'])]\n",
    "X_test = X_test[X_test.columns.drop(['HOUR', 'DAY', 'MONTH'])]\n",
    "\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "humidity  pressure  temperature  weather  wind direction  wind speed  \\\n149434      77.0    1008.0   292.910000       16           170.0         6.0   \n140854      45.0    1007.0   300.830000        3           140.0         7.0   \n288700      81.0    1027.0   303.429333       23           218.0         3.0   \n316913      50.0    1007.0   297.400000        0           250.0         5.0   \n91933       72.0    1023.0   288.200000        0             0.0         0.0   \n...          ...       ...          ...      ...             ...         ...   \n186987      65.0    1013.0   304.310000       23            84.0         0.0   \n154025      55.0    1043.0   284.482000       23           110.0         4.0   \n199040      46.0    1031.0   299.098500       23            77.0         3.0   \n230752      66.0    1016.0   286.700000       16           340.0         4.0   \n189066      79.0    1010.0   299.130000       23           203.0         2.0   \n\n        city    YEAR  HOUR_SIN      HOUR_COS       DAY_SIN   DAY_COS  \\\n149434     1  2014.0  0.258819 -9.659258e-01 -9.510565e-01  0.309017   \n140854     1  2013.0 -0.258819  9.659258e-01  2.079117e-01  0.978148   \n288700     4  2014.0 -0.965926 -2.588190e-01 -4.067366e-01 -0.913545   \n316913     5  2012.0 -1.000000 -1.836970e-16  9.945219e-01  0.104528   \n91933      6  2012.0  0.500000  8.660254e-01 -2.449294e-16  1.000000   \n...      ...     ...       ...           ...           ...       ...   \n186987     2  2013.0 -0.866025 -5.000000e-01  9.945219e-01  0.104528   \n154025     1  2014.0 -1.000000 -1.836970e-16  2.079117e-01  0.978148   \n199040     2  2014.0 -0.707107  7.071068e-01 -9.945219e-01 -0.104528   \n230752     0  2013.0 -0.965926 -2.588190e-01  9.510565e-01  0.309017   \n189066     2  2013.0  0.965926 -2.588190e-01  4.067366e-01  0.913545   \n\n           MONTH_SIN     MONTH_COS  \n149434  8.660254e-01 -5.000000e-01  \n140854  5.000000e-01 -8.660254e-01  \n288700 -1.000000e+00 -1.836970e-16  \n316913 -8.660254e-01  5.000000e-01  \n91933  -5.000000e-01  8.660254e-01  \n...              ...           ...  \n186987  1.224647e-16 -1.000000e+00  \n154025 -5.000000e-01  8.660254e-01  \n199040 -8.660254e-01  5.000000e-01  \n230752  8.660254e-01 -5.000000e-01  \n189066 -1.000000e+00 -1.836970e-16  \n\n[152626 rows x 14 columns]\n"
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[ 0.33472517 -1.36303928  0.28250634 ...  0.41439979  1.30456295\n  -0.78228429]\n [-1.29631557 -1.47527672  1.20351227 ...  1.35560703  0.77804012\n  -1.29405949]\n [ 0.53860526  0.76947203  1.50578517 ... -1.30527141 -1.37969058\n  -0.08318637]\n ...\n [-1.24534554  1.21842178  1.00215851 ... -0.16729827 -1.18696984\n   0.61591156]\n [-0.22594508 -0.46513978 -0.43964604 ...  0.41439979  1.30456295\n  -0.78228429]\n [ 0.43666522 -1.13856441  1.0058216  ...  1.26473687 -1.37969058\n  -0.08318637]]\n"
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# Smote for resampling\n",
    "X_resampled, y_resampled = SMOTE().fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>col_0</th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>row_0</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>151397</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>151397</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "col_0   count\nrow_0        \n0      151397\n1      151397"
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=y_resampled, columns='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fiveCVLogisticRegression(xtrain, ytrain, C_grid):\n",
    "    scores_train = np.zeros(len(C_grid))\n",
    "    scores_test = np.zeros(len(C_grid))\n",
    "    for i in range(5):\n",
    "        print('Run ', i+1)\n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "        \n",
    "        model = LogisticRegression(penalty='l2')\n",
    "\n",
    "        grid={\"C\":C_grid, \"penalty\":[\"l2\"]} # l2 ridge\n",
    "        logreg=LogisticRegression()\n",
    "        logreg_cv=GridSearchCV(logreg,grid,cv=kfold,return_train_score=True)\n",
    "        logreg_cv.fit(xtrain, ytrain)\n",
    "\n",
    "        # View the accuracy score\n",
    "        # print('Best score for training data:', logreg_cv.best_score_,\"\\n\") \n",
    "\n",
    "        # View the best parameters for the model found using grid search\n",
    "        print('Best lambda:',1.0/logreg_cv.best_estimator_.C,\"\\n\") \n",
    "\n",
    "\n",
    "        # print(\"Training set score for logreg_cv: \",  logreg_cv.cv_results_['mean_train_score'])\n",
    "        # print(\"Testing  set score for logreg_cv: \", logreg_cv.cv_results_['mean_test_score'])\n",
    "\n",
    "        scores_train += logreg_cv.cv_results_['mean_train_score']\n",
    "        scores_test += logreg_cv.cv_results_['mean_test_score']\n",
    "\n",
    "    scores_train = scores_train/5\n",
    "    scores_test = scores_test/5\n",
    "   \n",
    "\n",
    "    print('avg train score: ', scores_train)\n",
    "    print('avg test score: ', scores_test)\n",
    "    return scores_train, scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Run  1\nBest lambda: 1000.0 \n\nRun  2\nBest lambda: 1000.0 \n\nRun  3\nBest lambda: 1000.0 \n\nRun  4\nBest lambda: 1000.0 \n\nRun  5\nBest lambda: 1000.0 \n\navg train score:  [0.99194764 0.99194764 0.99194764 0.99194764 0.99194764 0.99194764\n 0.99194764 0.99194764]\navg test score:  [0.99194764 0.99194764 0.99194764 0.99194764 0.99194764 0.99194764\n 0.99194764 0.99194764]\n"
    }
   ],
   "source": [
    "C_grid = [1e-3, 1e-2, 1e-1, 1, 1e1, 50.0, 1e2, 1e3]\n",
    "scores_train_std, scores_test_std = fiveCVLogisticRegression(X_resampled, y_train, C_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CVLogisticRegression(xtrain, ytrain, xtest, ytest, _lambda):\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    model = LogisticRegression(penalty='l2', C=1/_lambda)\n",
    "    model.fit(xtrain, ytrain)\n",
    "\n",
    "    train_score = 1 - model.score(xtrain, ytrain)\n",
    "    test_score = 1 - model.score(xtest, ytest)\n",
    "\n",
    "\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_error, avg_test_error = CVLogisticRegression(X_train, y_train, X_test, y_test, 1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {'Method': ['std'], \n",
    "        #  'lambda': [best_lambda_std, best_lambda_log, best_lambda_bin], \n",
    "        #  'Avg Val Error': [avg_val_error_std, avg_val_error_log, avg_val_error_bin], \n",
    "         'Train Error': [avg_train_error], \n",
    "        'Test Error': [avg_test_error]}\n",
    "df_table = pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>Train Error</th>\n      <th>Test Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>std</td>\n      <td>0.008052</td>\n      <td>0.007676</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Method  Train Error  Test Error\n0    std     0.008052    0.007676"
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "152626"
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}